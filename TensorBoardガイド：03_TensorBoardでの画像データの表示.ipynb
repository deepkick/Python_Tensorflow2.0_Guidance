{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "453e873b",
   "metadata": {},
   "source": [
    "# TensorBoardでの画像データの表示\n",
    "\n",
    "https://www.tensorflow.org/tensorboard/image_summaries?hl=ja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fed435",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "TensorFlowイメージ概要APIを使用して、簡単にテンソルと任意の画像を記録し、TensorBoardでそれらを表示することができます。これは、サンプルに非常に役立つことや、あなたの入力データを調べ、または層の重み視覚化および生成されたテンソルをすることができます。モデル開発の過程で役立つ画像として診断データをログに記録することもできます。\n",
    "\n",
    "このチュートリアルでは、Image SummaryAPIを使用してテンソルを画像として視覚化する方法を学習します。また、任意の画像を取得してテンソルに変換し、TensorBoardで視覚化する方法についても学習します。モデルのパフォーマンスを理解するのに役立つ画像の概要を使用する、シンプルでありながら実際の例を実行します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a187f",
   "metadata": {},
   "source": [
    "## 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "591ea783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b0d720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.7.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import io\n",
    "import itertools\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d8d676",
   "metadata": {},
   "source": [
    "## Fashion-MNISTデータセットをダウンロードする\n",
    "あなたには分類画像に簡単なニューラルネットワークを構築しようとしているファッション・MNISTのデータセット。このデータセットは、10のカテゴリのファッション製品の70,000の28x28グレースケール画像で構成され、カテゴリごとに7,000の画像があります。\n",
    "\n",
    "まず、データをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b98c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data. The data is already divided into train and test.\n",
    "# The labels are integers representing classes.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "    fashion_mnist.load_data()\n",
    "\n",
    "# Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7041534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape =  (60000, 28, 28)\n",
      "train_labels.shape =  (60000,)\n",
      "test_images.shape =  (10000, 28, 28)\n",
      "test_labels.shape =  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('train_images.shape = ', train_images.shape)\n",
    "print('train_labels.shape = ', train_labels.shape)\n",
    "print('test_images.shape = ', test_images.shape)\n",
    "print('test_labels.shape = ', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51bb8a7",
   "metadata": {},
   "source": [
    "## 単一の画像を視覚化する\n",
    "Image Summary APIがどのように機能するかを理解するために、TensorBoardのトレーニングセットの最初のトレーニング画像をログに記録するだけです。\n",
    "\n",
    "その前に、トレーニングデータの形状を調べてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "029e9a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (28, 28)\n",
      "Label:  9 -> Ankle boot\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \", train_images[0].shape)\n",
    "print(\"Label: \", train_labels[0], \"->\", class_names[train_labels[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5868c3",
   "metadata": {},
   "source": [
    "データセット内の各画像の形状は、高さと幅を表す形状のランク2テンソル（28、28）であることに注意してください。\n",
    "\n",
    "しかし、 tf.summary.image()を含む階数4のテンソル期待(batch_size, height, width, channels) 。したがって、テンソルの形状を変更する必要があります。\n",
    "\n",
    "だから、1枚の画像だけ、だログbatch_size画像がグレースケールのある1ですので、設定channels 1に。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dcd882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image for the Summary API.\n",
    "img = np.reshape(train_images[0], (-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e1f318",
   "metadata": {},
   "source": [
    "これで、この画像をログに記録してTensorBoardで表示する準備が整いました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34451746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out any prior log data.\n",
    "!rm -rf logs\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Using the file writer, log the reshaped image.\n",
    "with file_writer.as_default():\n",
    "  tf.summary.image(\"Training data\", img, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7c63d",
   "metadata": {},
   "source": [
    "次に、TensorBoardを使用して画像を調べます。 UIが起動するまで数秒待ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc558538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e360f3",
   "metadata": {},
   "source": [
    "ターミナルから以下を実行し、tensorboard 起動\n",
    "\n",
    "cd /Users/kaoru/opt/anaconda3/envs/py37_Kaggle_GreatBarrierReef/lib/python3.7/site-packages/tensorboard\n",
    "\n",
    "python main.py --logdir=/Users/kaoru/Documents/Python_Tensorflow2.0_Guidance/logs/train_data\n",
    "\n",
    "tensorboard 起動に成功したら、下記にアクセス  \n",
    "http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23c5ca",
   "metadata": {},
   "source": [
    "## 複数の画像を視覚化する\n",
    "1つのテンソルをログに記録するのは素晴らしいことですが、複数のトレーニング例をログに記録したい場合はどうでしょうか。\n",
    "\n",
    "単にあなたがにデータを渡すときにログに記録したい画像の数を指定tf.summary.image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f05005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_writer.as_default():\n",
    "  # Don't forget to reshape.\n",
    "  images = np.reshape(train_images[0:25], (-1, 28, 28, 1))\n",
    "  tf.summary.image(\"25 training data examples\", images, max_outputs=25, step=0)\n",
    "\n",
    "# %tensorboard --logdir logs/train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d949d1c4",
   "metadata": {},
   "source": [
    "## 任意の画像データのログ\n",
    "\n",
    "以下のコードでは、matplotlibの使用の素敵なグリッドとして最初の25枚の画像を記録しますsubplot()関数を。次に、TensorBoardでグリッドを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42be2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out prior logging data.\n",
    "!rm -rf logs/plots\n",
    "\n",
    "logdir = \"logs/plots/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "def plot_to_image(figure):\n",
    "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "  # Save the plot to a PNG in memory.\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png')\n",
    "  # Closing the figure prevents it from being displayed directly inside\n",
    "  # the notebook.\n",
    "  plt.close(figure)\n",
    "  buf.seek(0)\n",
    "  # Convert PNG buffer to TF image\n",
    "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "  # Add the batch dimension\n",
    "  image = tf.expand_dims(image, 0)\n",
    "  return image\n",
    "\n",
    "def image_grid():\n",
    "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
    "  # Create a figure to contain the plot.\n",
    "  figure = plt.figure(figsize=(10,10))\n",
    "  for i in range(25):\n",
    "    # Start next subplot.\n",
    "    plt.subplot(5, 5, i + 1, title=class_names[train_labels[i]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "\n",
    "  return figure\n",
    "\n",
    "# Prepare the plot\n",
    "figure = image_grid()\n",
    "# Convert to image and log\n",
    "with file_writer.as_default():\n",
    "  tf.summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
    "\n",
    "#%tensorboard --logdir logs/plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ddc795",
   "metadata": {},
   "source": [
    "## 画像分類器の構築\n",
    "これを実際の例と一緒にまとめます。結局のところ、あなたは機械学習を行うためにここにいて、きれいな写真をプロットするのではありません！\n",
    "\n",
    "画像の要約を使用して、Fashion-MNISTデータセットの単純な分類器をトレーニングしながらモデルがどの程度うまく機能しているかを理解します。\n",
    "\n",
    "まず、非常に単純なモデルを作成してコンパイルし、オプティマイザーと損失関数を設定します。コンパイルステップでは、途中で分類子の精度をログに記録することも指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fe10ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57cdd61",
   "metadata": {},
   "source": [
    "分類器を訓練するとき、それは見るために便利です混同行列を。混同行列は、分類器がテストデータに対してどのように実行されているかについての詳細な知識を提供します。\n",
    "\n",
    "混同行列を計算する関数を定義します。あなたは便利な使いますScikit-学ぶこれを行うための機能を、その後、matplotlibのを使用して、それをプロットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ac7df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "  \"\"\"\n",
    "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "  Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "  \"\"\"\n",
    "  figure = plt.figure(figsize=(8, 8))\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "  plt.title(\"Confusion matrix\")\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(class_names))\n",
    "  plt.xticks(tick_marks, class_names, rotation=45)\n",
    "  plt.yticks(tick_marks, class_names)\n",
    "\n",
    "  # Compute the labels from the normalized confusion matrix.\n",
    "  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "  # Use white text if squares are dark; otherwise black.\n",
    "  threshold = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92275f6",
   "metadata": {},
   "source": [
    "これで、分類器をトレーニングし、途中で混同行列を定期的に記録する準備が整いました。\n",
    "\n",
    "これがあなたがすることです：\n",
    "\n",
    "1. 作成Keras TensorBoardコールバックを基本的な指標をログに記録します\n",
    "2. 作成Keras LambdaCallbackのすべてのエポックの終わりに混同行列をログに記録します\n",
    "3. Model.fit（）を使用してモデルをトレーニングし、両方のコールバックを必ず渡すようにします\n",
    "\n",
    "トレーニングが進むにつれて、下にスクロールしてTensorBoardが起動することを確認します。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd7a2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out prior logging data.\n",
    "!rm -rf logs/image\n",
    "\n",
    "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Define the basic TensorBoard callback.\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95b28566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "  # Use the model to predict the values from the validation dataset.\n",
    "  test_pred_raw = model.predict(test_images)\n",
    "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "  # Calculate the confusion matrix.\n",
    "  cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
    "  # Log the confusion matrix as an image summary.\n",
    "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "  cm_image = plot_to_image(figure)\n",
    "\n",
    "  # Log the confusion matrix as an image summary.\n",
    "  with file_writer_cm.as_default():\n",
    "    tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "917cf08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faba31a7bd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start TensorBoard.\n",
    "#%tensorboard --logdir logs/image\n",
    "\n",
    "# Train the classifier.\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    verbose=0, # Suppress chatty output\n",
    "    callbacks=[tensorboard_callback, cm_callback],\n",
    "    validation_data=(test_images, test_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f782c58",
   "metadata": {},
   "source": [
    "トレインセットと検証セットの両方で精度が向上していることに注意してください。それは良い兆候です。しかし、モデルはデータの特定のサブセットでどのように機能していますか？\n",
    "\n",
    "「画像」タブを選択して、ログに記録された混同行列を視覚化します。フルサイズの混同行列を表示するには、左上の[実際の画像サイズを表示する]をオンにします。\n",
    "\n",
    "デフォルトでは、ダッシュボードには、最後にログに記録されたステップまたはエポックの画像の概要が表示されます。スライダーを使用して、以前の混同行列を表示します。トレーニングが進むにつれて行列がどのように大きく変化するかに注目してください。暗い正方形が対角線に沿って合体し、残りの行列は0と白に向かう傾向があります。これは、トレーニングが進むにつれて分類器が向上していることを意味します。すごい仕事！\n",
    "\n",
    "混同行列は、この単純なモデルにいくつかの問題があることを示しています。大きな進歩にもかかわらず、シャツ、Tシャツ、プルオーバーは互いに混乱しています。モデルにはさらに作業が必要です。\n",
    "\n",
    "あなたが興味を持っている場合、でこのモデルを改善しようと、畳み込みネットワーク（CNN）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a5d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
